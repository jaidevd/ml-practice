{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e51994-3dae-4d54-adfa-9dff8cf4ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import random\n",
    "\n",
    "with open('twitter.json', 'r') as fin:\n",
    "    docs = [json.loads(k) for k in fin.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64449fe3-9ba4-4da2-bc2a-e188b4027b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Hello, World!',\n",
       "  'labels': [{'start': 0, 'end': -1, 'label': 'PER'},\n",
       "   {'start': 0, 'end': -1, 'label': 'LOC'}]}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output\n",
    "[\n",
    "    {\n",
    "        \"text\": \"Hello, World!\",\n",
    "        \"labels\": [\n",
    "            {\"start\": 0, \"end\": -1, \"label\": \"PER\"},\n",
    "            {\"start\": 0, \"end\": -1, \"label\": \"LOC\"},\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d3970d1-b572-4437-90b3-2d47d40a5251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Najib Razak', 'PER'), ('Emergency Ops Centre', 'LOC')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgdoc = random.choice(docs)\n",
    "\n",
    "doc = nlp(orgdoc['text'])\n",
    "labels, offsets = orgdoc['entities'], orgdoc['annotation_offsets']\n",
    "\n",
    "def merge_offsets(doc, labels, offsets):\n",
    "    spans = []\n",
    "    for label, (start, end) in zip(labels, offsets):\n",
    "        if label == 'O':\n",
    "            continue\n",
    "        span = doc.char_span(start, end, label.split('-')[-1], alignment_mode=\"expand\")\n",
    "        spans.append(span)\n",
    "    spans = spacy.util.filter_spans(spans)\n",
    "    doc.set_ents(spans)\n",
    "    return doc\n",
    "\n",
    "doc = merge_offsets(doc, labels, offsets)\n",
    "\n",
    "matcher = spacy.matcher.Matcher(nlp.vocab)\n",
    "\n",
    "# Make ORG, PER, LOC matchers\n",
    "orgpattern = [\n",
    "   {'ENT_TYPE': 'ORG'},\n",
    "   {'ENT_TYPE': 'ORG', 'OP': '*'}\n",
    "]\n",
    "locpattern = [\n",
    "   {'ENT_TYPE': 'LOC'},\n",
    "   {'ENT_TYPE': 'LOC', 'OP': '*'}\n",
    "]\n",
    "perpattern = [\n",
    "   {'ENT_TYPE': 'PER'},\n",
    "   {'ENT_TYPE': 'PER', 'OP': '*'}\n",
    "\n",
    "]\n",
    "matcher.add(\"ORG\", [orgpattern])\n",
    "matcher.add(\"LOC\", [locpattern])\n",
    "matcher.add(\"PER\", [perpattern])\n",
    "\n",
    "[(d.text, d.label_) for d in spacy.util.filter_spans([spacy.tokens.Span(doc, start, stop, nlp.vocab.strings[id_]) for id_, start, stop in matcher(doc)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "891cec5a-2cc3-44ee-97d2-9b0cd4f5ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = []\n",
    "for orgdoc in docs:\n",
    "    doc = nlp(orgdoc['text'])\n",
    "    labels, offsets = orgdoc['entities'], orgdoc['annotation_offsets']\n",
    "    doc = merge_offsets(doc, labels, offsets)\n",
    "    spans = spacy.util.filter_spans([spacy.tokens.Span(doc, start, stop, nlp.vocab.strings[id_]) for id_, start, stop in matcher(doc)])\n",
    "    payload.append({\n",
    "        'text': doc.text,\n",
    "        'labels': [{\"start\": s.start_char, \"end\": s.end_char, 'label': s.label_} for s in spans]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e03124-ede3-4a31-82dc-7950d1a842de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5512c3fd-384f-459c-a6c9-61b4c72fcda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ner-train.json', 'w') as fin:\n",
    "    json.dump(payload, fin, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b8ec4-eb75-4306-80ce-563729f0fd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
